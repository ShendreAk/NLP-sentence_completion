{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Project Gutenberg's Etext of Tom Swift And His Submarine Boat*\n",
      "\n",
      "#4 in the Victor Appleton's Tom Swift Series\n",
      "\n",
      "We name these Etext files as they are numbered in the books,\n",
      "\n",
      "i.e. This is #4 in the series so the file name is 04tomxxx.xxx,\n",
      "\n",
      "where the x's are place holders for editon # and file type such\n",
      "\n",
      "as 04tom10.txt and 04tom10.zip, when we do a .htm, 04tom10h.htm\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Copyright laws are changing all over the world, be sure to check\n",
      "\n",
      "the copyright laws for your country before posting these files\n"
     ]
    }
   ],
   "source": [
    "#open data file\n",
    "with open(\"data/holmes.txt\", 'r', encoding='utf-8') as f:\n",
    "  data = f.read()\n",
    "  print(data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removal of special characters\n",
    "def removeSpecialChar(data):\n",
    "  #remove special characters\n",
    "  data = re.sub(r'[^a-zA-Z0-9\\s]', \"\", data)\n",
    "  #remove extra spaces\n",
    "  data = re.sub(\" +\", \" \", data)\n",
    "\n",
    "  \n",
    "  return data\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing\n",
    "def preprocess(data):\n",
    "  sentences = data.split(\"\\n\")\n",
    "  for i in range(len(sentences)):\n",
    "    sentences[i] = removeSpecialChar(sentences[i])\n",
    "  \n",
    "  sentences = [s.strip() for s in sentences]\n",
    "  #drop empty sentences\n",
    "  sentences = [ s for s in sentences if len(sentences)> 0]\n",
    "  tokenizer = []\n",
    "  for s in sentences:\n",
    "    s = s.lower()\n",
    "    tokenizer.append(s)\n",
    "  return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokenized_sentence = preprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize words\n",
    "tokenizer = Tokenizer(oov_token ='<oov>')\n",
    "tokenizer.fit_on_texts(Tokenized_sentence)\n",
    "total_words = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<oov>': 1,\n",
       " 'the': 2,\n",
       " 'and': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'a': 6,\n",
       " 'in': 7,\n",
       " 'i': 8,\n",
       " 'he': 9,\n",
       " 'was': 10,\n",
       " 'that': 11,\n",
       " 'it': 12,\n",
       " 'his': 13,\n",
       " 'you': 14,\n",
       " 'with': 15,\n",
       " 'had': 16,\n",
       " 'for': 17,\n",
       " 'as': 18,\n",
       " 'her': 19,\n",
       " 'she': 20,\n",
       " 'but': 21,\n",
       " 'at': 22,\n",
       " 'not': 23,\n",
       " 'is': 24,\n",
       " 'on': 25,\n",
       " 'be': 26,\n",
       " 'him': 27,\n",
       " 'my': 28,\n",
       " 'have': 29,\n",
       " 'they': 30,\n",
       " 'by': 31,\n",
       " 'said': 32,\n",
       " 'this': 33,\n",
       " 'me': 34,\n",
       " 'all': 35,\n",
       " 'from': 36,\n",
       " 'were': 37,\n",
       " 'which': 38,\n",
       " 'so': 39,\n",
       " 'or': 40,\n",
       " 'one': 41,\n",
       " 'if': 42,\n",
       " 'there': 43,\n",
       " 'we': 44,\n",
       " 'no': 45,\n",
       " 'when': 46,\n",
       " 'an': 47,\n",
       " 'would': 48,\n",
       " 'their': 49,\n",
       " 'what': 50,\n",
       " 'them': 51,\n",
       " 'who': 52,\n",
       " 'been': 53,\n",
       " 'out': 54,\n",
       " 'are': 55,\n",
       " 'up': 56,\n",
       " 'then': 57,\n",
       " 'could': 58,\n",
       " 'do': 59,\n",
       " 'will': 60,\n",
       " 'into': 61,\n",
       " 'more': 62,\n",
       " 'your': 63,\n",
       " 'now': 64,\n",
       " 'man': 65,\n",
       " 'very': 66,\n",
       " 'little': 67,\n",
       " 'upon': 68,\n",
       " 'some': 69,\n",
       " 'about': 70,\n",
       " 'its': 71,\n",
       " 'time': 72,\n",
       " 'like': 73,\n",
       " 'than': 74,\n",
       " 'did': 75,\n",
       " 'any': 76,\n",
       " 'mr': 77,\n",
       " 'other': 78,\n",
       " 'see': 79,\n",
       " 'well': 80,\n",
       " 'know': 81,\n",
       " 'before': 82,\n",
       " 'down': 83,\n",
       " 'only': 84,\n",
       " 'over': 85,\n",
       " 'our': 86,\n",
       " 'after': 87,\n",
       " 'come': 88,\n",
       " 'made': 89,\n",
       " 'has': 90,\n",
       " 'came': 91,\n",
       " 'never': 92,\n",
       " 'how': 93,\n",
       " 'two': 94,\n",
       " 'should': 95,\n",
       " 'great': 96,\n",
       " 'good': 97,\n",
       " 'old': 98,\n",
       " 'can': 99,\n",
       " 'go': 100,\n",
       " 'such': 101,\n",
       " 'us': 102,\n",
       " 'much': 103,\n",
       " 'must': 104,\n",
       " 'may': 105,\n",
       " 'back': 106,\n",
       " 'again': 107,\n",
       " 'where': 108,\n",
       " 'here': 109,\n",
       " 'these': 110,\n",
       " 'way': 111,\n",
       " 'went': 112,\n",
       " 'himself': 113,\n",
       " 'first': 114,\n",
       " 'might': 115,\n",
       " 'dont': 116,\n",
       " 'say': 117,\n",
       " 'long': 118,\n",
       " 'own': 119,\n",
       " 'day': 120,\n",
       " 'am': 121,\n",
       " 'think': 122,\n",
       " 'too': 123,\n",
       " 'away': 124,\n",
       " 'men': 125,\n",
       " 'eyes': 126,\n",
       " 'through': 127,\n",
       " 'get': 128,\n",
       " 'thought': 129,\n",
       " 'even': 130,\n",
       " 'just': 131,\n",
       " 'make': 132,\n",
       " 'without': 133,\n",
       " 'last': 134,\n",
       " 'hand': 135,\n",
       " 'most': 136,\n",
       " 'take': 137,\n",
       " 'life': 138,\n",
       " 'face': 139,\n",
       " 'every': 140,\n",
       " 'still': 141,\n",
       " 'looked': 142,\n",
       " 'those': 143,\n",
       " 'being': 144,\n",
       " 'head': 145,\n",
       " 'saw': 146,\n",
       " 'young': 147,\n",
       " 'shall': 148,\n",
       " 'got': 149,\n",
       " 'mrs': 150,\n",
       " 'people': 151,\n",
       " 'nothing': 152,\n",
       " 'while': 153,\n",
       " 'house': 154,\n",
       " 'many': 155,\n",
       " 'off': 156,\n",
       " 'tell': 157,\n",
       " 'once': 158,\n",
       " 'though': 159,\n",
       " 'yet': 160,\n",
       " 'ever': 161,\n",
       " 'look': 162,\n",
       " 'found': 163,\n",
       " 'place': 164,\n",
       " 'took': 165,\n",
       " 'seemed': 166,\n",
       " 'right': 167,\n",
       " 'another': 168,\n",
       " 'why': 169,\n",
       " 'night': 170,\n",
       " 'under': 171,\n",
       " 'things': 172,\n",
       " 'let': 173,\n",
       " 'going': 174,\n",
       " 'asked': 175,\n",
       " 'same': 176,\n",
       " 'left': 177,\n",
       " 'put': 178,\n",
       " 'give': 179,\n",
       " 'always': 180,\n",
       " 'sir': 181,\n",
       " 'thing': 182,\n",
       " 'three': 183,\n",
       " 'something': 184,\n",
       " 'new': 185,\n",
       " 'told': 186,\n",
       " 'heard': 187,\n",
       " 'mind': 188,\n",
       " 'door': 189,\n",
       " 'knew': 190,\n",
       " 'room': 191,\n",
       " 'king': 192,\n",
       " 'father': 193,\n",
       " 'against': 194,\n",
       " 'turned': 195,\n",
       " 'moment': 196,\n",
       " 'world': 197,\n",
       " 'woman': 198,\n",
       " 'side': 199,\n",
       " 'better': 200,\n",
       " 'miss': 201,\n",
       " 'quite': 202,\n",
       " 'oh': 203,\n",
       " 'enough': 204,\n",
       " 'home': 205,\n",
       " 'each': 206,\n",
       " 'because': 207,\n",
       " 'yes': 208,\n",
       " 'done': 209,\n",
       " 'hands': 210,\n",
       " 'myself': 211,\n",
       " 'seen': 212,\n",
       " 'mother': 213,\n",
       " 'want': 214,\n",
       " 'stood': 215,\n",
       " 'work': 216,\n",
       " 'far': 217,\n",
       " 'cried': 218,\n",
       " 'heart': 219,\n",
       " 'love': 220,\n",
       " 'im': 221,\n",
       " 'soon': 222,\n",
       " 'years': 223,\n",
       " 'began': 224,\n",
       " 'ill': 225,\n",
       " 'find': 226,\n",
       " 'few': 227,\n",
       " 'between': 228,\n",
       " 'felt': 229,\n",
       " 'among': 230,\n",
       " 'days': 231,\n",
       " 'part': 232,\n",
       " 'gave': 233,\n",
       " 'poor': 234,\n",
       " 'voice': 235,\n",
       " 'small': 236,\n",
       " 'name': 237,\n",
       " 'having': 238,\n",
       " 'lady': 239,\n",
       " 'set': 240,\n",
       " 'next': 241,\n",
       " 'both': 242,\n",
       " 'white': 243,\n",
       " 'morning': 244,\n",
       " 'round': 245,\n",
       " 'dear': 246,\n",
       " 'herself': 247,\n",
       " 'anything': 248,\n",
       " 'course': 249,\n",
       " 'whom': 250,\n",
       " 'girl': 251,\n",
       " 'end': 252,\n",
       " 'called': 253,\n",
       " 'almost': 254,\n",
       " 'looking': 255,\n",
       " 'until': 256,\n",
       " 'money': 257,\n",
       " 'rather': 258,\n",
       " 'light': 259,\n",
       " 'perhaps': 260,\n",
       " 'sure': 261,\n",
       " 'sat': 262,\n",
       " 'words': 263,\n",
       " 'word': 264,\n",
       " 'friend': 265,\n",
       " 'nor': 266,\n",
       " 'etext': 267,\n",
       " 'whole': 268,\n",
       " 'since': 269,\n",
       " 'gone': 270,\n",
       " 'replied': 271,\n",
       " 'however': 272,\n",
       " 'project': 273,\n",
       " 'also': 274,\n",
       " 'till': 275,\n",
       " 'country': 276,\n",
       " 'brought': 277,\n",
       " 'kind': 278,\n",
       " 'half': 279,\n",
       " 'together': 280,\n",
       " 'indeed': 281,\n",
       " 'says': 282,\n",
       " 'water': 283,\n",
       " 'behind': 284,\n",
       " 'boy': 285,\n",
       " 'best': 286,\n",
       " 'feet': 287,\n",
       " 'along': 288,\n",
       " 'keep': 289,\n",
       " 'air': 290,\n",
       " 'tom': 291,\n",
       " 'within': 292,\n",
       " 'lay': 293,\n",
       " 'passed': 294,\n",
       " 'de': 295,\n",
       " 'black': 296,\n",
       " 'open': 297,\n",
       " 'answered': 298,\n",
       " 'hear': 299,\n",
       " 'thou': 300,\n",
       " 'taken': 301,\n",
       " 'full': 302,\n",
       " 'death': 303,\n",
       " 'matter': 304,\n",
       " 'cant': 305,\n",
       " 'thats': 306,\n",
       " 'less': 307,\n",
       " 'others': 308,\n",
       " 'alone': 309,\n",
       " 'returned': 310,\n",
       " 'near': 311,\n",
       " 'god': 312,\n",
       " 'believe': 313,\n",
       " 'wife': 314,\n",
       " 'wish': 315,\n",
       " 'least': 316,\n",
       " 'hope': 317,\n",
       " 'does': 318,\n",
       " 'hour': 319,\n",
       " 'whose': 320,\n",
       " 'hundred': 321,\n",
       " 'coming': 322,\n",
       " 'themselves': 323,\n",
       " 'lord': 324,\n",
       " 'above': 325,\n",
       " 'leave': 326,\n",
       " 'help': 327,\n",
       " 'didnt': 328,\n",
       " 'child': 329,\n",
       " 'really': 330,\n",
       " 'fell': 331,\n",
       " 'dead': 332,\n",
       " 'high': 333,\n",
       " 'used': 334,\n",
       " 'mean': 335,\n",
       " 'person': 336,\n",
       " 'son': 337,\n",
       " 'fire': 338,\n",
       " 'friends': 339,\n",
       " 'ive': 340,\n",
       " 'speak': 341,\n",
       " 'suddenly': 342,\n",
       " 'often': 343,\n",
       " 'already': 344,\n",
       " 'children': 345,\n",
       " 'lost': 346,\n",
       " 'read': 347,\n",
       " 'times': 348,\n",
       " 'cannot': 349,\n",
       " 'rest': 350,\n",
       " 'either': 351,\n",
       " 'arms': 352,\n",
       " 'true': 353,\n",
       " 'p': 354,\n",
       " 'evening': 355,\n",
       " 'business': 356,\n",
       " 'large': 357,\n",
       " 'call': 358,\n",
       " 'towards': 359,\n",
       " 'sort': 360,\n",
       " 'town': 361,\n",
       " 'held': 362,\n",
       " 'around': 363,\n",
       " 'feel': 364,\n",
       " 'whether': 365,\n",
       " 'thus': 366,\n",
       " 'certain': 367,\n",
       " 'hard': 368,\n",
       " 'talk': 369,\n",
       " 'four': 370,\n",
       " 'dark': 371,\n",
       " 'women': 372,\n",
       " 'present': 373,\n",
       " 'given': 374,\n",
       " 'big': 375,\n",
       " 'use': 376,\n",
       " 'table': 377,\n",
       " 'bed': 378,\n",
       " 'gentleman': 379,\n",
       " 'manner': 380,\n",
       " 'everything': 381,\n",
       " 'strange': 382,\n",
       " 'john': 383,\n",
       " 'toward': 384,\n",
       " 'return': 385,\n",
       " 'ground': 386,\n",
       " 'across': 387,\n",
       " 'body': 388,\n",
       " 'kept': 389,\n",
       " 'ask': 390,\n",
       " 'master': 391,\n",
       " 'red': 392,\n",
       " 'city': 393,\n",
       " 'close': 394,\n",
       " 'short': 395,\n",
       " 'care': 396,\n",
       " 'point': 397,\n",
       " 'chapter': 398,\n",
       " 'second': 399,\n",
       " 'pretty': 400,\n",
       " 'year': 401,\n",
       " 'turn': 402,\n",
       " 'case': 403,\n",
       " 'spoke': 404,\n",
       " 'became': 405,\n",
       " 'else': 406,\n",
       " 'captain': 407,\n",
       " 'family': 408,\n",
       " 'sometimes': 409,\n",
       " 'wont': 410,\n",
       " 'fact': 411,\n",
       " 'street': 412,\n",
       " 'making': 413,\n",
       " 'suppose': 414,\n",
       " 'sight': 415,\n",
       " 'road': 416,\n",
       " 'five': 417,\n",
       " 'rose': 418,\n",
       " 'understand': 419,\n",
       " 'land': 420,\n",
       " 'sent': 421,\n",
       " 'thousand': 422,\n",
       " 'known': 423,\n",
       " 'brother': 424,\n",
       " 'wanted': 425,\n",
       " 'form': 426,\n",
       " 'o': 427,\n",
       " 'appeared': 428,\n",
       " 'means': 429,\n",
       " 'hair': 430,\n",
       " 'power': 431,\n",
       " 'followed': 432,\n",
       " 'window': 433,\n",
       " 'hold': 434,\n",
       " 'footnote': 435,\n",
       " 'ten': 436,\n",
       " 'reason': 437,\n",
       " 'itself': 438,\n",
       " 'answer': 439,\n",
       " 'several': 440,\n",
       " 'fear': 441,\n",
       " 'beautiful': 442,\n",
       " 'sea': 443,\n",
       " 'strong': 444,\n",
       " 'ready': 445,\n",
       " 'live': 446,\n",
       " 'horse': 447,\n",
       " 'public': 448,\n",
       " 'nature': 449,\n",
       " 'ran': 450,\n",
       " 'state': 451,\n",
       " 'general': 452,\n",
       " 'remember': 453,\n",
       " 'thee': 454,\n",
       " 'doubt': 455,\n",
       " 'hours': 456,\n",
       " 'happy': 457,\n",
       " 'need': 458,\n",
       " 'please': 459,\n",
       " 'tried': 460,\n",
       " 'sound': 461,\n",
       " 'letter': 462,\n",
       " 'story': 463,\n",
       " 'met': 464,\n",
       " 'order': 465,\n",
       " 'received': 466,\n",
       " 'idea': 467,\n",
       " 'fine': 468,\n",
       " 'walked': 469,\n",
       " 'theres': 470,\n",
       " 'opened': 471,\n",
       " 'fellow': 472,\n",
       " 'hes': 473,\n",
       " 'eye': 474,\n",
       " 'taking': 475,\n",
       " 'low': 476,\n",
       " 'during': 477,\n",
       " 'gutenberg': 478,\n",
       " 'show': 479,\n",
       " 'prince': 480,\n",
       " 'cold': 481,\n",
       " 'longer': 482,\n",
       " 'question': 483,\n",
       " 'try': 484,\n",
       " 'entered': 485,\n",
       " 'beyond': 486,\n",
       " 'free': 487,\n",
       " 'continued': 488,\n",
       " 'truth': 489,\n",
       " 'none': 490,\n",
       " 'mine': 491,\n",
       " 'reached': 492,\n",
       " 'earth': 493,\n",
       " 'able': 494,\n",
       " 'bad': 495,\n",
       " 'arm': 496,\n",
       " 'added': 497,\n",
       " 'run': 498,\n",
       " 'river': 499,\n",
       " 'saying': 500,\n",
       " 'bring': 501,\n",
       " 'daughter': 502,\n",
       " 'youre': 503,\n",
       " 'sun': 504,\n",
       " 'silence': 505,\n",
       " 'possible': 506,\n",
       " 'glad': 507,\n",
       " 'neither': 508,\n",
       " 'forward': 509,\n",
       " 'yourself': 510,\n",
       " 'sense': 511,\n",
       " 'deep': 512,\n",
       " 'afraid': 513,\n",
       " 'husband': 514,\n",
       " 'feeling': 515,\n",
       " 'ye': 516,\n",
       " 'fair': 517,\n",
       " 'human': 518,\n",
       " 'stopped': 519,\n",
       " 'become': 520,\n",
       " 'past': 521,\n",
       " 'carried': 522,\n",
       " 'drew': 523,\n",
       " 'church': 524,\n",
       " 'ought': 525,\n",
       " 'doing': 526,\n",
       " 'thy': 527,\n",
       " 'happened': 528,\n",
       " 'exclaimed': 529,\n",
       " 'certainly': 530,\n",
       " 'soul': 531,\n",
       " 'company': 532,\n",
       " 'laughed': 533,\n",
       " 'below': 534,\n",
       " 'slowly': 535,\n",
       " 'book': 536,\n",
       " 'front': 537,\n",
       " 'different': 538,\n",
       " 'green': 539,\n",
       " 'gold': 540,\n",
       " 'interest': 541,\n",
       " 'clear': 542,\n",
       " 'wind': 543,\n",
       " 'chance': 544,\n",
       " 'cut': 545,\n",
       " 'minutes': 546,\n",
       " 'forth': 547,\n",
       " 'thinking': 548,\n",
       " 'number': 549,\n",
       " 'boys': 550,\n",
       " 'led': 551,\n",
       " 'laid': 552,\n",
       " 'stand': 553,\n",
       " 'lived': 554,\n",
       " 'late': 555,\n",
       " 'smile': 556,\n",
       " 'trees': 557,\n",
       " 'meet': 558,\n",
       " 'lips': 559,\n",
       " 'wall': 560,\n",
       " 'foot': 561,\n",
       " 'standing': 562,\n",
       " 'six': 563,\n",
       " 'therefore': 564,\n",
       " 'sleep': 565,\n",
       " 'trouble': 566,\n",
       " 'blue': 567,\n",
       " 'doctor': 568,\n",
       " 'sister': 569,\n",
       " 'beside': 570,\n",
       " 'seem': 571,\n",
       " 'caught': 572,\n",
       " 'struck': 573,\n",
       " 'change': 574,\n",
       " 'couldnt': 575,\n",
       " 'wouldnt': 576,\n",
       " 'wild': 577,\n",
       " 'wrong': 578,\n",
       " 'walk': 579,\n",
       " 'party': 580,\n",
       " 'real': 581,\n",
       " 'wonder': 582,\n",
       " 'blood': 583,\n",
       " 'getting': 584,\n",
       " 'm': 585,\n",
       " 'ah': 586,\n",
       " 'except': 587,\n",
       " 'girls': 588,\n",
       " 'pay': 589,\n",
       " 'seems': 590,\n",
       " 'note': 591,\n",
       " 'later': 592,\n",
       " 'chair': 593,\n",
       " 'mouth': 594,\n",
       " 'deal': 595,\n",
       " 'fall': 596,\n",
       " 'pleasure': 597,\n",
       " 'nearly': 598,\n",
       " 'account': 599,\n",
       " 'further': 600,\n",
       " 'age': 601,\n",
       " 'subject': 602,\n",
       " 'corner': 603,\n",
       " 'horses': 604,\n",
       " 'information': 605,\n",
       " 'bear': 606,\n",
       " 'early': 607,\n",
       " 'play': 608,\n",
       " 'cause': 609,\n",
       " 'stay': 610,\n",
       " 'plain': 611,\n",
       " 'grew': 612,\n",
       " 'sitting': 613,\n",
       " 'wait': 614,\n",
       " 'remained': 615,\n",
       " 'miles': 616,\n",
       " 'hardly': 617,\n",
       " 'distance': 618,\n",
       " 'heavy': 619,\n",
       " 'following': 620,\n",
       " 'floor': 621,\n",
       " 'week': 622,\n",
       " 'english': 623,\n",
       " 'turning': 624,\n",
       " 'quiet': 625,\n",
       " 'id': 626,\n",
       " 'seeing': 627,\n",
       " 'save': 628,\n",
       " 'spirit': 629,\n",
       " 'paper': 630,\n",
       " 'youll': 631,\n",
       " 'pass': 632,\n",
       " 'comes': 633,\n",
       " 'started': 634,\n",
       " 'ago': 635,\n",
       " 'presently': 636,\n",
       " 'war': 637,\n",
       " 'although': 638,\n",
       " 'living': 639,\n",
       " 'married': 640,\n",
       " 'length': 641,\n",
       " 'character': 642,\n",
       " 'dinner': 643,\n",
       " 'tree': 644,\n",
       " 'paid': 645,\n",
       " 'instead': 646,\n",
       " 'send': 647,\n",
       " 'whatever': 648,\n",
       " 'silent': 649,\n",
       " 'thoughts': 650,\n",
       " 'purpose': 651,\n",
       " 'law': 652,\n",
       " 'line': 653,\n",
       " 'easy': 654,\n",
       " 'etexts': 655,\n",
       " 'figure': 656,\n",
       " 'knows': 657,\n",
       " 'common': 658,\n",
       " 'ones': 659,\n",
       " 'attention': 660,\n",
       " 'secret': 661,\n",
       " 'immediately': 662,\n",
       " 'isnt': 663,\n",
       " 'aunt': 664,\n",
       " 'filled': 665,\n",
       " 'tone': 666,\n",
       " 'uncle': 667,\n",
       " 'court': 668,\n",
       " 'london': 669,\n",
       " 'c': 670,\n",
       " 'books': 671,\n",
       " 'broken': 672,\n",
       " 'moved': 673,\n",
       " 'sit': 674,\n",
       " 'ship': 675,\n",
       " 'showed': 676,\n",
       " 'top': 677,\n",
       " 'tears': 678,\n",
       " 'talking': 679,\n",
       " 'loved': 680,\n",
       " 'died': 681,\n",
       " 'art': 682,\n",
       " 'hat': 683,\n",
       " 'garden': 684,\n",
       " 'straight': 685,\n",
       " 'rich': 686,\n",
       " 'em': 687,\n",
       " 'bit': 688,\n",
       " 'waiting': 689,\n",
       " 'die': 690,\n",
       " 'boat': 691,\n",
       " 'mans': 692,\n",
       " 'trying': 693,\n",
       " 'sudden': 694,\n",
       " 'strength': 695,\n",
       " 'instant': 696,\n",
       " 'quickly': 697,\n",
       " 'view': 698,\n",
       " 'stop': 699,\n",
       " 'minute': 700,\n",
       " 'observed': 701,\n",
       " 'besides': 702,\n",
       " 'shook': 703,\n",
       " 'england': 704,\n",
       " 'position': 705,\n",
       " 'presence': 706,\n",
       " 'youth': 707,\n",
       " 'raised': 708,\n",
       " 'twenty': 709,\n",
       " 'outside': 710,\n",
       " 'bright': 711,\n",
       " 'peace': 712,\n",
       " 'month': 713,\n",
       " 'meant': 714,\n",
       " 'stone': 715,\n",
       " 'appearance': 716,\n",
       " 'usual': 717,\n",
       " 'afternoon': 718,\n",
       " 'hall': 719,\n",
       " 'ladies': 720,\n",
       " 'princess': 721,\n",
       " 'broke': 722,\n",
       " 'natural': 723,\n",
       " 'beauty': 724,\n",
       " 'glass': 725,\n",
       " 'cry': 726,\n",
       " 'st': 727,\n",
       " 'knight': 728,\n",
       " 'beneath': 729,\n",
       " 'necessary': 730,\n",
       " 'watch': 731,\n",
       " 'months': 732,\n",
       " 'expression': 733,\n",
       " 'learned': 734,\n",
       " 'force': 735,\n",
       " 'desire': 736,\n",
       " 'anne': 737,\n",
       " 'queen': 738,\n",
       " 'heaven': 739,\n",
       " 'expected': 740,\n",
       " 'laugh': 741,\n",
       " 'fast': 742,\n",
       " 'follow': 743,\n",
       " 'eat': 744,\n",
       " 'fathers': 745,\n",
       " 'george': 746,\n",
       " 'wood': 747,\n",
       " 'sweet': 748,\n",
       " 'effect': 749,\n",
       " 'kings': 750,\n",
       " 'direction': 751,\n",
       " 'particular': 752,\n",
       " 'joy': 753,\n",
       " 'afterwards': 754,\n",
       " 'forest': 755,\n",
       " 'wished': 756,\n",
       " 'beginning': 757,\n",
       " 'whats': 758,\n",
       " 'conversation': 759,\n",
       " 'breath': 760,\n",
       " 'placed': 761,\n",
       " 'carry': 762,\n",
       " 'single': 763,\n",
       " 'thank': 764,\n",
       " 'fight': 765,\n",
       " 'sorry': 766,\n",
       " 'surprise': 767,\n",
       " 'aint': 768,\n",
       " 'opinion': 769,\n",
       " 'dropped': 770,\n",
       " 'service': 771,\n",
       " 'village': 772,\n",
       " 'piece': 773,\n",
       " 'youve': 774,\n",
       " 'act': 775,\n",
       " 'closed': 776,\n",
       " 'dress': 777,\n",
       " 'today': 778,\n",
       " 'steps': 779,\n",
       " 'hill': 780,\n",
       " 'receive': 781,\n",
       " 'makes': 782,\n",
       " 'nobody': 783,\n",
       " 'danger': 784,\n",
       " 'office': 785,\n",
       " 'threw': 786,\n",
       " 'scarcely': 787,\n",
       " 'running': 788,\n",
       " 'probably': 789,\n",
       " 'society': 790,\n",
       " 'object': 791,\n",
       " 'third': 792,\n",
       " 'l': 793,\n",
       " 'clothes': 794,\n",
       " 'history': 795,\n",
       " 'knowledge': 796,\n",
       " 'impossible': 797,\n",
       " 'leaving': 798,\n",
       " 'shut': 799,\n",
       " 'step': 800,\n",
       " 'worth': 801,\n",
       " 'brown': 802,\n",
       " 'escape': 803,\n",
       " 'tomorrow': 804,\n",
       " 'neck': 805,\n",
       " 'easily': 806,\n",
       " 'dollars': 807,\n",
       " 'shoulder': 808,\n",
       " 'repeated': 809,\n",
       " 'speaking': 810,\n",
       " 'box': 811,\n",
       " 'shes': 812,\n",
       " 'sky': 813,\n",
       " 'journey': 814,\n",
       " 'letters': 815,\n",
       " 'worse': 816,\n",
       " 'ears': 817,\n",
       " 'exactly': 818,\n",
       " 'creature': 819,\n",
       " 'castle': 820,\n",
       " 'south': 821,\n",
       " 'reach': 822,\n",
       " 'terrible': 823,\n",
       " 'glance': 824,\n",
       " 'pleased': 825,\n",
       " 'notice': 826,\n",
       " 'occasion': 827,\n",
       " 'prepared': 828,\n",
       " 'watched': 829,\n",
       " 'talked': 830,\n",
       " 'lying': 831,\n",
       " 'drink': 832,\n",
       " 'print': 833,\n",
       " 'oclock': 834,\n",
       " 'french': 835,\n",
       " 'visit': 836,\n",
       " 'covered': 837,\n",
       " 'pleasant': 838,\n",
       " 'giving': 839,\n",
       " 'houses': 840,\n",
       " 'spot': 841,\n",
       " 'school': 842,\n",
       " 'darkness': 843,\n",
       " 'path': 844,\n",
       " 'perfectly': 845,\n",
       " 'changed': 846,\n",
       " 'seven': 847,\n",
       " 'states': 848,\n",
       " 'smiled': 849,\n",
       " 'gentlemen': 850,\n",
       " 'pale': 851,\n",
       " 'marry': 852,\n",
       " 'written': 853,\n",
       " 'quick': 854,\n",
       " 'palace': 855,\n",
       " 'wonderful': 856,\n",
       " 'wasnt': 857,\n",
       " 'places': 858,\n",
       " 'forget': 859,\n",
       " 'north': 860,\n",
       " 'duty': 861,\n",
       " 'greater': 862,\n",
       " 'hot': 863,\n",
       " 'dog': 864,\n",
       " 'fresh': 865,\n",
       " 'honour': 866,\n",
       " 'walls': 867,\n",
       " 'discovered': 868,\n",
       " 'fortune': 869,\n",
       " 'battle': 870,\n",
       " 'legs': 871,\n",
       " 'looks': 872,\n",
       " 'arrived': 873,\n",
       " 'marriage': 874,\n",
       " 'lie': 875,\n",
       " 'write': 876,\n",
       " 'wide': 877,\n",
       " 'stranger': 878,\n",
       " 'ii': 879,\n",
       " 'copy': 880,\n",
       " 'chief': 881,\n",
       " 'unless': 882,\n",
       " 'merely': 883,\n",
       " 'scene': 884,\n",
       " 'crowd': 885,\n",
       " 'shoulders': 886,\n",
       " 'tall': 887,\n",
       " 'island': 888,\n",
       " 'picture': 889,\n",
       " 'lives': 890,\n",
       " 'circumstances': 891,\n",
       " 'finally': 892,\n",
       " 'fifty': 893,\n",
       " 'waited': 894,\n",
       " 'private': 895,\n",
       " 'spring': 896,\n",
       " 'cast': 897,\n",
       " 'hung': 898,\n",
       " 'shot': 899,\n",
       " 'gate': 900,\n",
       " 'summer': 901,\n",
       " 'yellow': 902,\n",
       " 'soft': 903,\n",
       " 'heads': 904,\n",
       " 'safe': 905,\n",
       " 'news': 906,\n",
       " 'pocket': 907,\n",
       " 'directly': 908,\n",
       " 'copyright': 909,\n",
       " 'emperor': 910,\n",
       " 'food': 911,\n",
       " 'passing': 912,\n",
       " 'mighty': 913,\n",
       " 'sharp': 914,\n",
       " '1': 915,\n",
       " 'fallen': 916,\n",
       " 'reply': 917,\n",
       " 'fingers': 918,\n",
       " 'warm': 919,\n",
       " 'begin': 920,\n",
       " 'touch': 921,\n",
       " 'latter': 922,\n",
       " 'happiness': 923,\n",
       " 'entirely': 924,\n",
       " 'sword': 925,\n",
       " 'middle': 926,\n",
       " 'east': 927,\n",
       " 'tired': 928,\n",
       " 'surprised': 929,\n",
       " 'fixed': 930,\n",
       " 'paul': 931,\n",
       " 'lot': 932,\n",
       " 'evil': 933,\n",
       " 'bank': 934,\n",
       " 'game': 935,\n",
       " 'silver': 936,\n",
       " 'whispered': 937,\n",
       " 'bound': 938,\n",
       " 'guess': 939,\n",
       " 'likely': 940,\n",
       " 'fancy': 941,\n",
       " '2': 942,\n",
       " 'somewhat': 943,\n",
       " 'opportunity': 944,\n",
       " 'future': 945,\n",
       " 'killed': 946,\n",
       " 'army': 947,\n",
       " 'former': 948,\n",
       " 'seat': 949,\n",
       " 'goes': 950,\n",
       " 'break': 951,\n",
       " 'born': 952,\n",
       " 'simple': 953,\n",
       " 'knowing': 954,\n",
       " 'simply': 955,\n",
       " 'experience': 956,\n",
       " 'grave': 957,\n",
       " 'flowers': 958,\n",
       " 'madame': 959,\n",
       " 'perfect': 960,\n",
       " 'everybody': 961,\n",
       " 'holding': 962,\n",
       " 'promise': 963,\n",
       " 'walking': 964,\n",
       " 'curious': 965,\n",
       " 'surely': 966,\n",
       " 'dream': 967,\n",
       " 'declared': 968,\n",
       " 'golden': 969,\n",
       " 'trust': 970,\n",
       " 'condition': 971,\n",
       " 'peter': 972,\n",
       " 'ancient': 973,\n",
       " 'streets': 974,\n",
       " 'important': 975,\n",
       " 'mere': 976,\n",
       " 'field': 977,\n",
       " 'inside': 978,\n",
       " 'shore': 979,\n",
       " 'mary': 980,\n",
       " 'faces': 981,\n",
       " 'learn': 982,\n",
       " 'statement': 983,\n",
       " 'race': 984,\n",
       " 'forgotten': 985,\n",
       " 'sake': 986,\n",
       " 'moments': 987,\n",
       " 'medium': 988,\n",
       " 'finished': 989,\n",
       " 'start': 990,\n",
       " 'jane': 991,\n",
       " 'respect': 992,\n",
       " 'board': 993,\n",
       " 'west': 994,\n",
       " 'companion': 995,\n",
       " 'opposite': 996,\n",
       " 'mothers': 997,\n",
       " 'speech': 998,\n",
       " 'determined': 999,\n",
       " 'moon': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenized_sentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#creating sequence\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sequences \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43mTokenized_sentence\u001b[49m:\n\u001b[1;32m      4\u001b[0m   list_ \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mtexts_to_sequences([s])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(list_)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tokenized_sentence' is not defined"
     ]
    }
   ],
   "source": [
    "#creating sequence\n",
    "sequences = []\n",
    "for s in Tokenized_sentence:\n",
    "  list_ = tokenizer.texts_to_sequences([s])[0]\n",
    "  for i in range(1,len(list_)):\n",
    "    n_gram_seq = list_[:i+1]\n",
    "    sequences.append(n_gram_seq)\n",
    "    \n",
    "#padding seq\n",
    "max_seq_len = max([len(x) for x in sequences])\n",
    "input_seq = np.array(pad_sequences(sequences, maxlen=max_seq_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_seq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X , labels \u001b[38;5;241m=\u001b[39m \u001b[43minput_seq\u001b[49m[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], input_seq[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m Y \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(labels, num_classes\u001b[38;5;241m=\u001b[39mtotal_words)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_seq' is not defined"
     ]
    }
   ],
   "source": [
    "X , labels = input_seq[:,:-1], input_seq[:, -1]\n",
    "Y = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=2)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words),100)\n",
    "model.add(Bidirectional(LSTM(150)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val,y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model = model.to_json()\n",
    "with open(\"sentComLstm.json\", 'w') as file:\n",
    "  file.write(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentComLstm.json\", 'r') as model_file:\n",
    "  model_json = model_file.read()\n",
    "  model = model_from_json(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(history.history['loss'], label='Train_loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation_loss')\n",
    "plt.title('Train v/s Validation Loss')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation_accuracy')\n",
    "plt.title('Train v/s Validation Loss')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(model=model, query_text):\n",
    "  list_ = tokenizer.text_to_sequence([query_text])[0]\n",
    "  token = pad_sequences([list_], maxlen= max_seq_len, padding ='pre')\n",
    "  predict = model.predict(token, verbose =1)\n",
    "  print(\"predict[0]: \",predict[0])\n",
    "  top_five_index = np.argsort(predict[0])[::-1][:5]\n",
    "  top_words = []\n",
    "  for i in top_five_index:\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "      if idx == i:\n",
    "        top_words.append(word)\n",
    "        break\n",
    "  return top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(query_text):\n",
    "  words = predict_next(model, query_text)\n",
    "  results = []\n",
    "  for word in words:\n",
    "    results.append(f'{query_text} {word}')\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected result: \", y_test[10], \"Observed result: \", display_result(X_test[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
